name: Benchmarks

on:
  push:
  pull_request:
  workflow_dispatch:

jobs:
  run-benchmarks:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ensure data/results dirs
        run: mkdir -p data results

      - name: Generate trace if missing (deterministic)
        run: |
          python - <<'PY'
import json, random, os
p = "data/freq_wins_50k.jsonl"
if not os.path.exists(p):
    random.seed(42)
    hot = [f"hot-{i}" for i in range(50)]
    cold = [f"cold-{i}" for i in range(2000)]
    with open(p, "w", encoding="utf-8") as f:
        for _ in range(5000):
            key = random.choice(hot) if random.random() < 0.6 else random.choice(cold)
            f.write(json.dumps({"prompt": key, "response": f"response-for-{key}"}) + "\n")
print("trace_ready:", p)
PY

      - name: Sanity check files
        run: |
          ls -lah data || true
          python - <<'PY'
import os, itertools
p = "data/freq_wins_50k.jsonl"
print("exists:", os.path.exists(p), "size:", os.path.getsize(p) if os.path.exists(p) else 0)
if os.path.exists(p):
    with open(p, "r", encoding="utf-8") as f:
        for i, line in zip(range(2), f):
            print(f"line{i+1}:", line.strip()[:200])
PY

      - name: Run baseline
        run: |
          python3 bench_gptcache.py \
            --trace data/freq_wins_50k.jsonl \
            --dim 512 --capacity 102400 \
            --base-lat 0.0005 --per-token 0.0002 \
            --mode baseline

      - name: Run TinyLFU
        run: |
          python3 bench_gptcache.py \
            --trace data/freq_wins_50k.jsonl \
            --dim 512 --capacity 102400 \
            --base-lat 0.0005 --per-token 0.0002 \
            --mode tinylfu_admit

      - name: Generate plots
        run: python3 plot_results.py

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: results/**
