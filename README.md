# Learning-Aware Caching for LLM Inference

This project extends the open-source [GPTCache](https://github.com/zilliztech/GPTCache) library with **learning-aware caching policies** that improve hit rates and reduce latency for Large-Language-Model (LLM) inference.

By default, GPTCache uses **Least Recently Used (LRU)** eviction, treating a 5-token greeting like a 3,000-token document. We introduce **admission strategies** (e.g., **TinyLFU doorkeeper**, admit on â‰¥2 sightings) that reduce cache pollution and boost hit rate and tail latency â€” **no API changes** required.

---

## âœ¨ Key Contributions

* **Baseline:** GPTCache with default **LRU (admit-all)** policy.
* **Extension:** **TinyLFU admission** (admit on â‰¥2nd sighting) to block one-shot inserts.
* **Future Work:** **Cost-Aware LRU (CA-LRU)** combining recency with estimated token cost, tuned online (bandit).
* **Perf Suite:** Benchmarks on realistic traces + synthetic hot/cold mixes with reproducible scripts.

---

## âš¡ Quickstart (pip-only, minimal)

> Works on Windows/macOS/Linux. Uses your provided traces in `data/`.

```powershell
# from repo root (PowerShell)
pip install -U pip gptcache faiss-cpu sqlalchemy numpy pandas matplotlib tqdm

# Run baseline â†’ TinyLFU â†’ plots on the provided trace
python bench_gptcache.py --trace data\freq_wins_50k.jsonl --dim 512 --capacity 25600 --base-lat 0.0005 --per-token 0.0002 --mode baseline
python bench_gptcache.py --trace data\freq_wins_50k.jsonl --dim 512 --capacity 25600 --base-lat 0.0005 --per-token 0.0002 --mode tinylfu_admit
python plot_results.py
```

Optional: run the second trace as well:

```powershell
python bench_gptcache.py --trace data\freq_resilient_50k.jsonl --dim 512 --capacity 25600 --base-lat 0.0005 --per-token 0.0002 --mode baseline
python bench_gptcache.py --trace data\freq_resilient_50k.jsonl --dim 512 --capacity 25600 --base-lat 0.0005 --per-token 0.0002 --mode tinylfu_admit
python plot_results.py
```

**Outputs:**

* Summaries: `results/gptcache_<mode>_cap<capacity>/summary.txt`
* CSV + plots: `results/benchmark_summary.csv`, `results/plots/*.png`

> Tip: If you ever change `--dim`, delete any old `*.db` / `*.index` files to avoid FAISS dimension mismatch.

---

## ðŸ§ª Whatâ€™s Being Compared?

* **baseline** â€” GPTCache admit-all + LRU
* **tinylfu\_admit** â€” TinyLFU doorkeeper: admit on â‰¥2nd sighting (same LRU under the hood)

**Shared settings:** `ExactMatch` similarity (threshold 1.0), SQLite + FAISS, hashed 512-dim embeddings for stable runtime, latency model
`lat(q) = base_lat + per_token * tokens(q)` with `base_lat=0.0005s`, `per_token=0.0002s`.

---

## ðŸ“Š Results (from the report)

**Trace:** `data/freq_wins_50k.jsonl`
**Capacities:** 50MB â‰ˆ 25,600 items â€¢ 100MB â‰ˆ 51,200 items â€¢ 200MB â‰ˆ 102,400 items

### 50 MB (\~25,600 items)

| Policy   | Hit (%)   | Mean (ms) | p95 (ms)  | p99 (ms)   | QPS       | Wall (s)   |
| -------- | --------- | --------- | --------- | ---------- | --------- | ---------- |
| Baseline | 53.48     | 16.83     | 52.93     | 223.50     | 92.44     | 540.88     |
| TinyLFU  | **57.96** | **15.66** | **50.49** | **216.94** | **98.10** | **509.68** |

### 100 MB (\~51,200 items)

| Policy   | Hit (%)   | Mean (ms) | p95 (ms)  | p99 (ms)   | QPS       | Wall (s)   |
| -------- | --------- | --------- | --------- | ---------- | --------- | ---------- |
| Baseline | 53.45     | 17.92     | 56.48     | 227.94     | 84.04     | 594.99     |
| TinyLFU  | **57.99** | **16.40** | **49.98** | **219.64** | **91.43** | **546.89** |

### 200 MB (\~102,400 items)

| Policy   | Hit (%)   | Mean (ms) | p95 (ms)  | p99 (ms)   | QPS       | Wall (s)   |
| -------- | --------- | --------- | --------- | ---------- | --------- | ---------- |
| Baseline | 53.39     | 17.63     | 55.32     | 225.49     | 86.16     | 580.33     |
| TinyLFU  | **58.01** | **16.59** | **50.54** | **220.28** | **89.82** | **556.64** |

**Takeaway:** TinyLFU admission consistently **raises hit rate (\~+4.5 pp)** and **reduces tail latency**, also shortening wall time under the same replay.

---

## ðŸ“ˆ Plots Produced

* `results/plots/hit_rate_vs_capacity.png`
* `results/plots/mean_vs_capacity.png`
* `results/plots/p95_vs_capacity.png`
* `results/plots/p99_vs_capacity.png`
* `results/plots/qps_vs_capacity.png`

(Generated by `plot_results.py` from the `summary.txt` files.)

---

## ðŸ§° Troubleshooting

* **FAISS install (Windows):** We install `faiss-cpu` via pip in the quickstart. If it ever fails, upgrade pip and retry:

  ```
  pip install -U pip
  pip install faiss-cpu
  ```
* **Changed `--dim`?** Delete old `*.db` and `*.index` files before rerunning.

---

## ðŸ“š References

* [GPTCache â€” ZillizTech](https://github.com/zilliztech/GPTCache)
* Oâ€™Neil et al., *TinyLFU: A Highly Efficient Cache Admission Policy*, ICS 2017.
