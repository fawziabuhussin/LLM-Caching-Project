# Learning-Aware Caching for LLM Inference

This project extends the open-source [GPTCache](https://github.com/zilliztech/GPTCache) library with **learning-aware caching policies** that improve hit rates and reduce latency for Large-Language-Model (LLM) inference.

By default, GPTCache uses **Least Recently Used (LRU)** eviction, treating a 5-token greeting like a 3,000-token document. We introduce **admission strategies** (e.g., **TinyLFU doorkeeper**, admit on â‰¥2 sightings) that reduce cache pollution and boost hit rate and tail latency â€” **no API changes** required.

---

## âœ¨ Key Contributions

* **Baseline:** GPTCache with default **LRU (admit-all)** policy.
* **Extension:** **TinyLFU admission** (admit on â‰¥2nd sighting) to block one-shot inserts.
* **Perf Suite:** Benchmarks on realistic traces + synthetic hot/cold mixes with reproducible scripts.

---

## âš¡ Quickstart (pip + reproducible benchmarks)

> Works on Windows/macOS/Linux. Uses traces in `data/`.  
> If `data/freq_wins_50k.jsonl` is missing, CI auto-generates a small deterministic trace so the workflow is self-contained.

### 0) Install
```bash
python3 -m venv .venv
source .venv/bin/activate         # Windows: .venv\Scripts\activate
python -m pip install --upgrade pip
pip install -r requirements.txt
````

### 1) Run benchmarks

Run baseline and TinyLFU at 200MB (\~102,400 items):

```bash
python3 bench_gptcache.py --trace data/freq_wins_50k.jsonl --dim 512 --capacity 102400 --base-lat 0.0005 --per-token 0.0002 --mode baseline

python3 bench_gptcache.py --trace data/freq_wins_50k.jsonl --dim 512 --capacity 102400 --base-lat 0.0005 --per-token 0.0002 --mode tinylfu_admit
```

### 2) Generate plots

```bash
python3 plot_results.py
```

**Outputs:**

* Summaries: `results/gptcache_<mode>_cap102400/summary.txt`
* CSV + plots: `results/benchmark_summary.csv`, `results/plots/*.png`

### 3) Clean (optional)

```bash
rm -rf results/ *.db *.index
```

> Tip: If you change `--dim`, delete old `*.db`/`*.index` before re-running (FAISS dimension mismatch).

---

## ðŸš€ One-Click Reproducibility (GitHub Actions)

This repo includes a GitHub Actions workflow at `.github/workflows/ci.yml`.
On every push/PR it:

1. Installs dependencies
2. Ensures `data/freq_wins_50k.jsonl` exists (auto-generates a small trace if missing)
3. Runs the two benchmark commands above
4. Generates plots
5. Uploads all `results/` as artifacts

Badge:
![Benchmarks](https://github.com/fawziabuhussin/LLM-Caching-Project/actions/workflows/ci.yml/badge.svg)

---

## ðŸ§ª Whatâ€™s Being Compared?

* **baseline** â€” GPTCache admit-all + LRU
* **tinylfu\_admit** â€” TinyLFU doorkeeper: admit on â‰¥2nd sighting (same LRU under the hood)

**Shared settings:** `ExactMatch` similarity (threshold 1.0), SQLite + FAISS, hashed 512-dim embeddings for stable runtime, latency model
`lat(q) = base_lat + per_token * tokens(q)` with `base_lat=0.0005s`, `per_token=0.0002s`.

---

## ðŸ“Š Results (from the report)

**Trace:** `data/freq_wins_50k.jsonl`
**Capacities:** 50MB â‰ˆ 25,600 items â€¢ 100MB â‰ˆ 51,200 items â€¢ 200MB â‰ˆ 102,400 items

### 50 MB (\~25,600 items)

| Policy   | Hit (%)   | Mean (ms) | p95 (ms)  | p99 (ms)   | QPS       | Wall (s)   |
| -------- | --------- | --------- | --------- | ---------- | --------- | ---------- |
| Baseline | 53.48     | 16.83     | 52.93     | 223.50     | 92.44     | 540.88     |
| TinyLFU  | **57.96** | **15.66** | **50.49** | **216.94** | **98.10** | **509.68** |

### 100 MB (\~51,200 items)

| Policy   | Hit (%)   | Mean (ms) | p95 (ms)  | p99 (ms)   | QPS       | Wall (s)   |
| -------- | --------- | --------- | --------- | ---------- | --------- | ---------- |
| Baseline | 53.45     | 17.92     | 56.48     | 227.94     | 84.04     | 594.99     |
| TinyLFU  | **57.99** | **16.40** | **49.98** | **219.64** | **91.43** | **546.89** |

### 200 MB (\~102,400 items)

| Policy   | Hit (%)   | Mean (ms) | p95 (ms)  | p99 (ms)   | QPS       | Wall (s)   |
| -------- | --------- | --------- | --------- | ---------- | --------- | ---------- |
| Baseline | 53.39     | 17.63     | 55.32     | 225.49     | 86.16     | 580.33     |
| TinyLFU  | **58.01** | **16.59** | **50.54** | **220.28** | **89.82** | **556.64** |

**Takeaway:** TinyLFU admission consistently **raises hit rate (\~+4.5 pp)** and **reduces tail latency**, also shortening wall time under the same replay.

---

## ðŸ“ˆ Plots Produced

* `results/plots/hit_rate_vs_capacity.png`
* `results/plots/mean_vs_capacity.png`
* `results/plots/p95_vs_capacity.png`
* `results/plots/p99_vs_capacity.png`
* `results/plots/qps_vs_capacity.png`

(Generated by `plot_results.py` from the `summary.txt` files.)

---

## ðŸ§° Troubleshooting

* **FAISS install (Windows):** We install `faiss-cpu` via pip in the quickstart. If it ever fails, upgrade pip and retry:

  ```bash
  pip install -U pip
  pip install faiss-cpu
  ```

* **Changed `--dim`?** Delete old `*.db` and `*.index` files before rerunning.

---

## ðŸ“š References

* [GPTCache â€” ZillizTech](https://github.com/zilliztech/GPTCache)
* Oâ€™Neil et al., *TinyLFU: A Highly Efficient Cache Admission Policy*, ICS 2017.

```
